{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c41ef966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4eae2c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_notebook = \"auto_markdown.ipynb\"\n",
    "with open(input_notebook, 'r', encoding='utf-8') as f:\n",
    "    nb_data = json.load(f)\n",
    "\n",
    "# Clean the data (Remove 'outputs')\n",
    "for cell in nb_data['cells']:\n",
    "    if 'outputs' in cell:\n",
    "        cell['outputs'] = []\n",
    "    if 'execution_count' in cell:\n",
    "        cell['execution_count'] = None\n",
    "        \n",
    "notebook_json_string = json.dumps(nb_data, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e453d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook = input_notebook.split(\".\")[0] + \"_with_md.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1c119f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_url = \"http://localhost:11434/v1\"\n",
    "ollama = OpenAI(api_key=\"ollama\", base_url=ollama_url)\n",
    "model = \"deepseek-coder-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cb07761",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"\n",
    "You are an expert Python Developer and Technical Writer.\n",
    "Your task is to create meaningful markdown text for the Python code blocks in a Jupyter Notebook\n",
    "\"\"\"\n",
    "\n",
    "def user_prompt_for(jupyter_nb):\n",
    "    return f\"\"\"\n",
    "Read this Jupyter Notebook JSON code it to a valid professional-grade  Jupyter Notebook (.ipynb) JSON string. \n",
    "Rules:\n",
    "No Code Changes: Do not modify, refactor, or delete any code within the code cells.\n",
    "Contextual Markdown: For every code cell in the notebook, insert a new markdown cell immediately preceding it.\n",
    "Content of Markdown: >    - Add a relevant Header (e.g., ### Data Processing).\n",
    "Write 2-3 sentences explaining the purpose of the code block.\n",
    "Describe any inputs, outputs, or side effects (like file saving or plotting).\n",
    "Preserve Metadata: Keep the existing kernelspec and language_info exactly as they are in the input.\n",
    "Output Format: Provide the complete, valid JSON for the updated .ipynb file. Output ONLY the JSON.\n",
    "\n",
    "Input Notebook JSON:\n",
    "```\n",
    "{jupyter_nb}\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db748e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_for(jupyter_nb):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(jupyter_nb)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29d7685c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_output(json):\n",
    "    with open(output_notebook, \"w\") as f:\n",
    "        f.write(json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca83ca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ollama.chat.completions.create(model=model, messages=messages_for(notebook_json_string))\n",
    "reply = response.choices[0].message.content\n",
    "reply.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "\n",
    "write_output(reply)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
